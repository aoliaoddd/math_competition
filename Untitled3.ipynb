{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\optuna\\progress_bar.py:49: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ae6ad0210b44e0ae66f993ca782541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "JoblibException",
     "evalue": "JoblibException\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nD:\\anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nD:\\anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002024F4D7ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002024F4D7ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    614                 tr.run()\n    615             except KeyboardInterrupt:\n    616                 pass\n    617         else:\n    618             try:\n--> 619                 self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    620             except KeyboardInterrupt:\n    621                 pass\n    622 \n    623 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    827                         self._timeouts = [x for x in self._timeouts\n    828                                           if x.callback is not None]\n    829                         heapq.heapify(self._timeouts)\n    830 \n    831                 for i in range(ncallbacks):\n--> 832                     self._run_callback(self._callbacks.popleft())\n        self._run_callback = <bound method IOLoop._run_callback of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n        self._callbacks.popleft = <built-in method popleft of collections.deque object>\n    833                 for timeout in due_timeouts:\n    834                     if timeout.callback is not None:\n    835                         self._run_callback(timeout.callback)\n    836                 # Closures may be holding on to a lot of memory, so allow\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<zmq.eventloop.ioloop.ZMQIOLoop object>, callback=functools.partial(<function wrap.<locals>.null_w....concurrent.Future object at 0x000002025212B0B8>))\n    600         \"\"\"Runs a callback with error handling.\n    601 \n    602         For use in subclasses.\n    603         \"\"\"\n    604         try:\n--> 605             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_w....concurrent.Future object at 0x000002025212B0B8>)\n    606             if ret is not None:\n    607                 from tornado import gen\n    608                 # Functions that return Futures typically swallow all\n    609                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<tornado.concurrent.Future object>,), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<tornado.concurrent.Future object>,)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in inner(f=None)\n   1147 \n   1148         if not self.future.done() or self.future is moment:\n   1149             def inner(f):\n   1150                 # Break a reference cycle to speed GC.\n   1151                 f = None # noqa\n-> 1152                 self.run()\n   1153             self.io_loop.add_future(\n   1154                 self.future, inner)\n   1155             return False\n   1156         return True\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in run(self=<tornado.gen.Runner object>)\n   1064                         finally:\n   1065                             # Break up a reference to itself\n   1066                             # for faster GC on CPython.\n   1067                             exc_info = None\n   1068                     else:\n-> 1069                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 6, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n   1070 \n   1071                     if stack_context._state.contexts is not orig_stack_contexts:\n   1072                         self.gen.throw(\n   1073                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    356         else:\n    357             try:\n    358                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    359             except QueueEmpty:\n    360                 return None\n--> 361         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    362 \n    363     @gen.coroutine\n    364     def dispatch_queue(self):\n    365         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    302                 # never actually yields, which in turn allows us to\n    303                 # use \"optional\" coroutines in critical path code without\n    304                 # performance penalty for the synchronous case.\n    305                 try:\n    306                     orig_stack_contexts = stack_context._state.contexts\n--> 307                     yielded = next(result)\n        yielded = undefined\n        result = <generator object dispatch_shell>\n    308                     if stack_context._state.contexts is not orig_stack_contexts:\n    309                         yielded = TracebackFuture()\n    310                         yielded.set_exception(\n    311                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}})\n    256             try:\n    257                 self.pre_handler_hook()\n    258             except Exception:\n    259                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    260             try:\n--> 261                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'fbedfd8a5a5d4f889cb6af724dc1bafd']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}}\n    262             except Exception:\n    263                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    264             except KeyboardInterrupt:\n    265                 # Ctrl-c shouldn't crash the kernel here.\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'fbedfd8a5a5d4f889cb6af724dc1bafd'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    302                 # never actually yields, which in turn allows us to\n    303                 # use \"optional\" coroutines in critical path code without\n    304                 # performance penalty for the synchronous case.\n    305                 try:\n    306                     orig_stack_contexts = stack_context._state.contexts\n--> 307                     yielded = next(result)\n        yielded = undefined\n        result = <generator object execute_request>\n    308                     if stack_context._state.contexts is not orig_stack_contexts:\n    309                         yielded = TracebackFuture()\n    310                         yielded.set_exception(\n    311                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'fbedfd8a5a5d4f889cb6af724dc1bafd'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}})\n    536             self._publish_execute_input(code, parent, self.execution_count)\n    537 \n    538         reply_content = yield gen.maybe_future(\n    539             self.do_execute(\n    540                 code, silent, store_history,\n--> 541                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    542             )\n    543         )\n    544 \n    545         # Flush output before sending the reply.\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', False, True, {}, True), **kwargs={})\n    302                 # never actually yields, which in turn allows us to\n    303                 # use \"optional\" coroutines in critical path code without\n    304                 # performance penalty for the synchronous case.\n    305                 try:\n    306                     orig_stack_contexts = stack_context._state.contexts\n--> 307                     yielded = next(result)\n        yielded = undefined\n        result = <generator object do_execute>\n    308                     if stack_context._state.contexts is not orig_stack_contexts:\n    309                         yielded = TracebackFuture()\n    310                         yielded.set_exception(\n    311                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    297                             shell.events.trigger('post_run_cell', res)\n    298             else:\n    299                 # runner isn't already running,\n    300                 # make synchronous call,\n    301                 # letting shell dispatch to loop runners\n--> 302                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n'\n        store_history = True\n        silent = False\n    303         finally:\n    304             self._restore_input()\n    305 \n    306         if res.error_before_exec is not None:\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n',), **kwargs={'silent': False, 'store_history': True})\n    534             )\n    535         self.payload_manager.write_payload(payload)\n    536 \n    537     def run_cell(self, *args, **kwargs):\n    538         self._last_traceback = None\n--> 539         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    540 \n    541     def _showtraceback(self, etype, evalue, stb):\n    542         # try to preserve ordering of tracebacks and print statements\n    543         sys.stdout.flush()\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.Import object>, <_ast.Import object>, <_ast.Import object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.FunctionDef object>, <_ast.FunctionDef object>, ...], cell_name='<ipython-input-2-508d851be536>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 20252119dd8, executio..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000020257738390, file \"<ipython-input-2-508d851be536>\", line 61>\n        result = <ExecutionResult object at 20252119dd8, executio..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000020257738390, file \"<ipython-input-2-508d851be536>\", line 61>, result=<ExecutionResult object at 20252119dd8, executio..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000020257738390, file \"<ipython-input-2-508d851be536>\", line 61>\n        self.user_global_ns = {'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))'], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'X':          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], '_': '', '__': '', '___': '', ...}\n        self.user_ns = {'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))'], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'X':          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], '_': '', '__': '', '___': '', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<ipython-input-2-508d851be536> in <module>()\n     56     print('随机森林最优参数：\\nbest_params:', study.best_trial.params,\n     57           '随机森林最优得分：\\nbest_score:', study.best_trial.value, '\\n')\n     58     \n     59     return study\n     60 \n---> 61 study_rf = optimizer_optuna_rf(100)\n     62 \n     63 with open('随机森林贝叶斯优化结果.txt', 'w') as f:\n     64     for key, value in study_rf.best_trial.params.items():\n     65         f.write(f'{key}: {value}\\n')\n\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<ipython-input-2-508d851be536> in optimizer_optuna_rf(n_trials=100)\n     49     validation_loss = cross_validate(reg, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n     50     return np.mean(validation_loss['test_score'])\n     51 \n     52 def optimizer_optuna_rf(n_trials):\n     53     study = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20, n_ei_candidates=30), direction='maximize')\n---> 54     study.optimize(optuna_objective_rf, n_trials=n_trials, show_progress_bar=True)\n     55     \n     56     print('随机森林最优参数：\\nbest_params:', study.best_trial.params,\n     57           '随机森林最优得分：\\nbest_score:', study.best_trial.value, '\\n')\n     58     \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\study.py in optimize(self=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, n_trials=100, timeout=None, n_jobs=1, catch=(), callbacks=None, gc_after_trial=False, show_progress_bar=True)\n    423             timeout=timeout,\n    424             n_jobs=n_jobs,\n    425             catch=catch,\n    426             callbacks=callbacks,\n    427             gc_after_trial=gc_after_trial,\n--> 428             show_progress_bar=show_progress_bar,\n        show_progress_bar = True\n    429         )\n    430 \n    431     def ask(\n    432         self, fixed_distributions: Optional[Dict[str, BaseDistribution]] = None\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py in _optimize(study=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, n_trials=100, timeout=None, n_jobs=1, catch=(), callbacks=None, gc_after_trial=False, show_progress_bar=True)\n     71                 catch,\n     72                 callbacks,\n     73                 gc_after_trial,\n     74                 reseed_sampler_rng=False,\n     75                 time_start=None,\n---> 76                 progress_bar=progress_bar,\n        progress_bar = <optuna.progress_bar._ProgressBar object>\n     77             )\n     78         else:\n     79             if n_jobs == -1:\n     80                 n_jobs = os.cpu_count() or 1\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py in _optimize_sequential(study=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, n_trials=100, timeout=None, catch=(), callbacks=None, gc_after_trial=False, reseed_sampler_rng=False, time_start=datetime.datetime(2024, 7, 6, 0, 21, 29, 101232), progress_bar=<optuna.progress_bar._ProgressBar object>)\n    155             elapsed_seconds = (datetime.datetime.now() - time_start).total_seconds()\n    156             if elapsed_seconds >= timeout:\n    157                 break\n    158 \n    159         try:\n--> 160             frozen_trial = _run_trial(study, func, catch)\n        frozen_trial = FrozenTrial(number=2, values=[-0.001057478380321...rial_id=2, state=TrialState.COMPLETE, value=None)\n        study = <optuna.study.study.Study object>\n        func = <function optuna_objective_rf>\n        catch = ()\n    161         finally:\n    162             # The following line mitigates memory problems that can be occurred in some\n    163             # environments (e.g., services that use computing containers such as CircleCI).\n    164             # Please refer to the following PR for further details:\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py in _run_trial(study=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, catch=())\n    191     func_err: Optional[Union[Exception, KeyboardInterrupt]] = None\n    192     func_err_fail_exc_info: Optional[Any] = None\n    193 \n    194     with get_heartbeat_thread(trial._trial_id, study._storage):\n    195         try:\n--> 196             value_or_values = func(trial)\n        value_or_values = None\n        func = <function optuna_objective_rf>\n        trial = <optuna.trial._trial.Trial object>\n    197         except exceptions.TrialPruned as e:\n    198             # TODO(mamu): Handle multi-objective cases.\n    199             state = TrialState.PRUNED\n    200             func_err = e\n\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<ipython-input-2-508d851be536> in optuna_objective_rf(trial=<optuna.trial._trial.Trial object>)\n     44                                 random_state=1412,\n     45                                 verbose=False,\n     46                                 n_jobs=-1)\n     47     \n     48     cv = KFold(n_splits=5, shuffle=True, random_state=1412)\n---> 49     validation_loss = cross_validate(reg, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n     50     return np.mean(validation_loss['test_score'])\n     51 \n     52 def optimizer_optuna_rf(n_trials):\n     53     study = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20, n_ei_candidates=30), direction='maximize')\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, groups=None, scoring='neg_mean_squared_error', cv=KFold(n_splits=5, random_state=1412, shuffle=True), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score='warn')\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=1412, shuffle=True)>\n        X =          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns]\n        y = 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nJoblibValueError                                   Sat Jul  6 00:26:08 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in retrieve(self=Parallel(n_jobs=-1))\n    735 %s\"\"\" % (this_report, exception.message)\n    736                     # Convert this to a JoblibException\n    737                     exception_type = _mk_exception(exception.etype)[0]\n    738                     exception = exception_type(report)\n    739 \n--> 740                     raise exception\n        exception = undefined\n    741 \n    742     def __call__(self, iterable):\n    743         if self._jobs:\n    744             raise ValueError('This Parallel instance is already running')\n\nJoblibValueError: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<string> in <module>()\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in spawn_main(pipe_handle=2796, parent_pid=5364, tracker_fd=None)\n    100         fd = msvcrt.open_osfhandle(new_handle, os.O_RDONLY)\n    101     else:\n    102         from . import semaphore_tracker\n    103         semaphore_tracker._semaphore_tracker._fd = tracker_fd\n    104         fd = pipe_handle\n--> 105     exitcode = _main(fd)\n        exitcode = undefined\n        fd = 3\n    106     sys.exit(exitcode)\n    107 \n    108 \n    109 def _main(fd):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in _main(fd=3)\n    113             preparation_data = reduction.pickle.load(from_parent)\n    114             prepare(preparation_data)\n    115             self = reduction.pickle.load(from_parent)\n    116         finally:\n    117             del process.current_process()._inheriting\n--> 118     return self._bootstrap()\n        self._bootstrap = <bound method BaseProcess._bootstrap of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    119 \n    120 \n    121 def _check_not_importing_main():\n    122     if getattr(process.current_process(), '_inheriting', False):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in _bootstrap(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n    253                 # delay finalization of the old process object until after\n    254                 # _run_after_forkers() is executed\n    255                 del old_process\n    256             util.info('child process calling self.run()')\n    257             try:\n--> 258                 self.run()\n        self.run = <bound method BaseProcess.run of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    259                 exitcode = 0\n    260             finally:\n    261                 util._exit_function()\n    262         except SystemExit as e:\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in run(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n     88     def run(self):\n     89         '''\n     90         Method to be run in sub-process; can be overridden in sub-class\n     91         '''\n     92         if self._target:\n---> 93             self._target(*self._args, **self._kwargs)\n        self._target = <function worker>\n        self._args = (<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, <sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, None, (), None, True)\n        self._kwargs = {}\n     94 \n     95     def start(self):\n     96         '''\n     97         Start child process\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\pool.py in worker(inqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, outqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, initializer=None, initargs=(), maxtasks=None, wrap_exception=True)\n    114             util.debug('worker got sentinel -- exiting')\n    115             break\n    116 \n    117         job, i, func, args, kwds = task\n    118         try:\n--> 119             result = (True, func(*args, **kwds))\n        result = undefined\n        func = <sklearn.externals.joblib._parallel_backends.SafeFunction object>\n        args = ()\n        kwds = {}\n    120         except Exception as e:\n    121             if wrap_exception and func is not _helper_reraises_exception:\n    122                 e = ExceptionWithTraceback(e, e.__traceback__)\n    123             result = (False, e)\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __call__(self=<sklearn.externals.joblib._parallel_backends.SafeFunction object>, *args=(), **kwargs={})\n    345     def __init__(self, func):\n    346         self.func = func\n    347 \n    348     def __call__(self, *args, **kwargs):\n    349         try:\n--> 350             return self.func(*args, **kwargs)\n        self.func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        args = ()\n        kwargs = {}\n    351         except KeyboardInterrupt:\n    352             # We capture the KeyboardInterrupt and reraise it as\n    353             # something different, as multiprocessing does not\n    354             # interrupt processing for a KeyboardInterrupt\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul  6 00:26:05 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29), {'class_weight': None, 'verbose': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29)\n        kwargs = {'class_weight': None, 'verbose': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None, tree_idx=0, n_trees=29, verbose=False, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1630984966, splitter='best')>\n        X = array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32)\n        y = array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]])\n        sample_weight = None\n        curr_sample_weight = array([3., 0., 0., ..., 2., 2., 1.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 121, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 1124, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 242, in fit\n    raise ValueError(\"max_features must be in (0, n_features]\")\nValueError: max_features must be in (0, n_features]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 699, in retrieve\n    self._output.extend(job.get(timeout=self.timeout))\n  File \"D:\\anaconda\\lib\\multiprocessing\\pool.py\", line 644, in get\n    raise self._value\n  File \"D:\\anaconda\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jul  6 00:26:05 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29), {'class_weight': None, 'verbose': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29)\n        kwargs = {'class_weight': None, 'verbose': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None, tree_idx=0, n_trees=29, verbose=False, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1630984966, splitter='best')>\n        X = array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32)\n        y = array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]])\n        sample_weight = None\n        curr_sample_weight = array([3., 0., 0., ..., 2., 2., 1.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 328, in fit\n    for i, t in enumerate(trees))\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 789, in __call__\n    self.retrieve()\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 740, in retrieve\n    raise exception\nsklearn.externals.joblib.my_exceptions.JoblibValueError: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<string> in <module>()\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in spawn_main(pipe_handle=2796, parent_pid=5364, tracker_fd=None)\n    100         fd = msvcrt.open_osfhandle(new_handle, os.O_RDONLY)\n    101     else:\n    102         from . import semaphore_tracker\n    103         semaphore_tracker._semaphore_tracker._fd = tracker_fd\n    104         fd = pipe_handle\n--> 105     exitcode = _main(fd)\n        exitcode = undefined\n        fd = 3\n    106     sys.exit(exitcode)\n    107 \n    108 \n    109 def _main(fd):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in _main(fd=3)\n    113             preparation_data = reduction.pickle.load(from_parent)\n    114             prepare(preparation_data)\n    115             self = reduction.pickle.load(from_parent)\n    116         finally:\n    117             del process.current_process()._inheriting\n--> 118     return self._bootstrap()\n        self._bootstrap = <bound method BaseProcess._bootstrap of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    119 \n    120 \n    121 def _check_not_importing_main():\n    122     if getattr(process.current_process(), '_inheriting', False):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in _bootstrap(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n    253                 # delay finalization of the old process object until after\n    254                 # _run_after_forkers() is executed\n    255                 del old_process\n    256             util.info('child process calling self.run()')\n    257             try:\n--> 258                 self.run()\n        self.run = <bound method BaseProcess.run of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    259                 exitcode = 0\n    260             finally:\n    261                 util._exit_function()\n    262         except SystemExit as e:\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in run(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n     88     def run(self):\n     89         '''\n     90         Method to be run in sub-process; can be overridden in sub-class\n     91         '''\n     92         if self._target:\n---> 93             self._target(*self._args, **self._kwargs)\n        self._target = <function worker>\n        self._args = (<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, <sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, None, (), None, True)\n        self._kwargs = {}\n     94 \n     95     def start(self):\n     96         '''\n     97         Start child process\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\pool.py in worker(inqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, outqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, initializer=None, initargs=(), maxtasks=None, wrap_exception=True)\n    114             util.debug('worker got sentinel -- exiting')\n    115             break\n    116 \n    117         job, i, func, args, kwds = task\n    118         try:\n--> 119             result = (True, func(*args, **kwds))\n        result = undefined\n        func = <sklearn.externals.joblib._parallel_backends.SafeFunction object>\n        args = ()\n        kwds = {}\n    120         except Exception as e:\n    121             if wrap_exception and func is not _helper_reraises_exception:\n    122                 e = ExceptionWithTraceback(e, e.__traceback__)\n    123             result = (False, e)\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __call__(self=<sklearn.externals.joblib._parallel_backends.SafeFunction object>, *args=(), **kwargs={})\n    345     def __init__(self, func):\n    346         self.func = func\n    347 \n    348     def __call__(self, *args, **kwargs):\n    349         try:\n--> 350             return self.func(*args, **kwargs)\n        self.func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        args = ()\n        kwargs = {}\n    351         except KeyboardInterrupt:\n    352             # We capture the KeyboardInterrupt and reraise it as\n    353             # something different, as multiprocessing does not\n    354             # interrupt processing for a KeyboardInterrupt\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul  6 00:26:05 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29), {'class_weight': None, 'verbose': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29)\n        kwargs = {'class_weight': None, 'verbose': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None, tree_idx=0, n_trees=29, verbose=False, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1630984966, splitter='best')>\n        X = array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32)\n        y = array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]])\n        sample_weight = None\n        curr_sample_weight = array([3., 0., 0., ..., 2., 2., 1.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\anaconda\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nJoblibValueError                                   Sat Jul  6 00:26:08 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in retrieve(self=Parallel(n_jobs=-1))\n    735 %s\"\"\" % (this_report, exception.message)\n    736                     # Convert this to a JoblibException\n    737                     exception_type = _mk_exception(exception.etype)[0]\n    738                     exception = exception_type(report)\n    739 \n--> 740                     raise exception\n        exception = undefined\n    741 \n    742     def __call__(self, iterable):\n    743         if self._jobs:\n    744             raise ValueError('This Parallel instance is already running')\n\nJoblibValueError: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<string> in <module>()\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in spawn_main(pipe_handle=2796, parent_pid=5364, tracker_fd=None)\n    100         fd = msvcrt.open_osfhandle(new_handle, os.O_RDONLY)\n    101     else:\n    102         from . import semaphore_tracker\n    103         semaphore_tracker._semaphore_tracker._fd = tracker_fd\n    104         fd = pipe_handle\n--> 105     exitcode = _main(fd)\n        exitcode = undefined\n        fd = 3\n    106     sys.exit(exitcode)\n    107 \n    108 \n    109 def _main(fd):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in _main(fd=3)\n    113             preparation_data = reduction.pickle.load(from_parent)\n    114             prepare(preparation_data)\n    115             self = reduction.pickle.load(from_parent)\n    116         finally:\n    117             del process.current_process()._inheriting\n--> 118     return self._bootstrap()\n        self._bootstrap = <bound method BaseProcess._bootstrap of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    119 \n    120 \n    121 def _check_not_importing_main():\n    122     if getattr(process.current_process(), '_inheriting', False):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in _bootstrap(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n    253                 # delay finalization of the old process object until after\n    254                 # _run_after_forkers() is executed\n    255                 del old_process\n    256             util.info('child process calling self.run()')\n    257             try:\n--> 258                 self.run()\n        self.run = <bound method BaseProcess.run of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    259                 exitcode = 0\n    260             finally:\n    261                 util._exit_function()\n    262         except SystemExit as e:\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in run(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n     88     def run(self):\n     89         '''\n     90         Method to be run in sub-process; can be overridden in sub-class\n     91         '''\n     92         if self._target:\n---> 93             self._target(*self._args, **self._kwargs)\n        self._target = <function worker>\n        self._args = (<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, <sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, None, (), None, True)\n        self._kwargs = {}\n     94 \n     95     def start(self):\n     96         '''\n     97         Start child process\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\pool.py in worker(inqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, outqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, initializer=None, initargs=(), maxtasks=None, wrap_exception=True)\n    114             util.debug('worker got sentinel -- exiting')\n    115             break\n    116 \n    117         job, i, func, args, kwds = task\n    118         try:\n--> 119             result = (True, func(*args, **kwds))\n        result = undefined\n        func = <sklearn.externals.joblib._parallel_backends.SafeFunction object>\n        args = ()\n        kwds = {}\n    120         except Exception as e:\n    121             if wrap_exception and func is not _helper_reraises_exception:\n    122                 e = ExceptionWithTraceback(e, e.__traceback__)\n    123             result = (False, e)\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __call__(self=<sklearn.externals.joblib._parallel_backends.SafeFunction object>, *args=(), **kwargs={})\n    345     def __init__(self, func):\n    346         self.func = func\n    347 \n    348     def __call__(self, *args, **kwargs):\n    349         try:\n--> 350             return self.func(*args, **kwargs)\n        self.func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        args = ()\n        kwargs = {}\n    351         except KeyboardInterrupt:\n    352             # We capture the KeyboardInterrupt and reraise it as\n    353             # something different, as multiprocessing does not\n    354             # interrupt processing for a KeyboardInterrupt\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul  6 00:26:05 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29), {'class_weight': None, 'verbose': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29)\n        kwargs = {'class_weight': None, 'verbose': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None, tree_idx=0, n_trees=29, verbose=False, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1630984966, splitter='best')>\n        X = array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32)\n        y = array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]])\n        sample_weight = None\n        curr_sample_weight = array([3., 0., 0., ..., 2., 2., 1.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nJoblibValueError                                   Sat Jul  6 00:26:08 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in retrieve(self=Parallel(n_jobs=-1))\n    735 %s\"\"\" % (this_report, exception.message)\n    736                     # Convert this to a JoblibException\n    737                     exception_type = _mk_exception(exception.etype)[0]\n    738                     exception = exception_type(report)\n    739 \n--> 740                     raise exception\n        exception = undefined\n    741 \n    742     def __call__(self, iterable):\n    743         if self._jobs:\n    744             raise ValueError('This Parallel instance is already running')\n\nJoblibValueError: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<string> in <module>()\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in spawn_main(pipe_handle=2796, parent_pid=5364, tracker_fd=None)\n    100         fd = msvcrt.open_osfhandle(new_handle, os.O_RDONLY)\n    101     else:\n    102         from . import semaphore_tracker\n    103         semaphore_tracker._semaphore_tracker._fd = tracker_fd\n    104         fd = pipe_handle\n--> 105     exitcode = _main(fd)\n        exitcode = undefined\n        fd = 3\n    106     sys.exit(exitcode)\n    107 \n    108 \n    109 def _main(fd):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in _main(fd=3)\n    113             preparation_data = reduction.pickle.load(from_parent)\n    114             prepare(preparation_data)\n    115             self = reduction.pickle.load(from_parent)\n    116         finally:\n    117             del process.current_process()._inheriting\n--> 118     return self._bootstrap()\n        self._bootstrap = <bound method BaseProcess._bootstrap of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    119 \n    120 \n    121 def _check_not_importing_main():\n    122     if getattr(process.current_process(), '_inheriting', False):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in _bootstrap(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n    253                 # delay finalization of the old process object until after\n    254                 # _run_after_forkers() is executed\n    255                 del old_process\n    256             util.info('child process calling self.run()')\n    257             try:\n--> 258                 self.run()\n        self.run = <bound method BaseProcess.run of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    259                 exitcode = 0\n    260             finally:\n    261                 util._exit_function()\n    262         except SystemExit as e:\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in run(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n     88     def run(self):\n     89         '''\n     90         Method to be run in sub-process; can be overridden in sub-class\n     91         '''\n     92         if self._target:\n---> 93             self._target(*self._args, **self._kwargs)\n        self._target = <function worker>\n        self._args = (<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, <sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, None, (), None, True)\n        self._kwargs = {}\n     94 \n     95     def start(self):\n     96         '''\n     97         Start child process\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\pool.py in worker(inqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, outqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, initializer=None, initargs=(), maxtasks=None, wrap_exception=True)\n    114             util.debug('worker got sentinel -- exiting')\n    115             break\n    116 \n    117         job, i, func, args, kwds = task\n    118         try:\n--> 119             result = (True, func(*args, **kwds))\n        result = undefined\n        func = <sklearn.externals.joblib._parallel_backends.SafeFunction object>\n        args = ()\n        kwds = {}\n    120         except Exception as e:\n    121             if wrap_exception and func is not _helper_reraises_exception:\n    122                 e = ExceptionWithTraceback(e, e.__traceback__)\n    123             result = (False, e)\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __call__(self=<sklearn.externals.joblib._parallel_backends.SafeFunction object>, *args=(), **kwargs={})\n    345     def __init__(self, func):\n    346         self.func = func\n    347 \n    348     def __call__(self, *args, **kwargs):\n    349         try:\n--> 350             return self.func(*args, **kwargs)\n        self.func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        args = ()\n        kwargs = {}\n    351         except KeyboardInterrupt:\n    352             # We capture the KeyboardInterrupt and reraise it as\n    353             # something different, as multiprocessing does not\n    354             # interrupt processing for a KeyboardInterrupt\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul  6 00:26:05 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29), {'class_weight': None, 'verbose': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29)\n        kwargs = {'class_weight': None, 'verbose': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None, tree_idx=0, n_trees=29, verbose=False, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1630984966, splitter='best')>\n        X = array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32)\n        y = array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]])\n        sample_weight = None\n        curr_sample_weight = array([3., 0., 0., ..., 2., 2., 1.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-508d851be536>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mstudy_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_optuna_rf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'随机森林贝叶斯优化结果.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-508d851be536>\u001b[0m in \u001b[0;36moptimizer_optuna_rf\u001b[1;34m(n_trials)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0moptimizer_optuna_rf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_startup_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_ei_candidates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptuna_objective_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     print('随机森林最优参数：\\nbest_params:', study.best_trial.params,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         )\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     ):\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-508d851be536>\u001b[0m in \u001b[0;36moptuna_objective_rf\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1412\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mvalidation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibException\u001b[0m: JoblibException\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nD:\\anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nD:\\anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002024F4D7ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002024F4D7ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    614                 tr.run()\n    615             except KeyboardInterrupt:\n    616                 pass\n    617         else:\n    618             try:\n--> 619                 self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    620             except KeyboardInterrupt:\n    621                 pass\n    622 \n    623 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    827                         self._timeouts = [x for x in self._timeouts\n    828                                           if x.callback is not None]\n    829                         heapq.heapify(self._timeouts)\n    830 \n    831                 for i in range(ncallbacks):\n--> 832                     self._run_callback(self._callbacks.popleft())\n        self._run_callback = <bound method IOLoop._run_callback of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n        self._callbacks.popleft = <built-in method popleft of collections.deque object>\n    833                 for timeout in due_timeouts:\n    834                     if timeout.callback is not None:\n    835                         self._run_callback(timeout.callback)\n    836                 # Closures may be holding on to a lot of memory, so allow\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<zmq.eventloop.ioloop.ZMQIOLoop object>, callback=functools.partial(<function wrap.<locals>.null_w....concurrent.Future object at 0x000002025212B0B8>))\n    600         \"\"\"Runs a callback with error handling.\n    601 \n    602         For use in subclasses.\n    603         \"\"\"\n    604         try:\n--> 605             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_w....concurrent.Future object at 0x000002025212B0B8>)\n    606             if ret is not None:\n    607                 from tornado import gen\n    608                 # Functions that return Futures typically swallow all\n    609                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<tornado.concurrent.Future object>,), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<tornado.concurrent.Future object>,)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in inner(f=None)\n   1147 \n   1148         if not self.future.done() or self.future is moment:\n   1149             def inner(f):\n   1150                 # Break a reference cycle to speed GC.\n   1151                 f = None # noqa\n-> 1152                 self.run()\n   1153             self.io_loop.add_future(\n   1154                 self.future, inner)\n   1155             return False\n   1156         return True\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in run(self=<tornado.gen.Runner object>)\n   1064                         finally:\n   1065                             # Break up a reference to itself\n   1066                             # for faster GC on CPython.\n   1067                             exc_info = None\n   1068                     else:\n-> 1069                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 6, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n   1070 \n   1071                     if stack_context._state.contexts is not orig_stack_contexts:\n   1072                         self.gen.throw(\n   1073                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    356         else:\n    357             try:\n    358                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    359             except QueueEmpty:\n    360                 return None\n--> 361         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    362 \n    363     @gen.coroutine\n    364     def dispatch_queue(self):\n    365         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    302                 # never actually yields, which in turn allows us to\n    303                 # use \"optional\" coroutines in critical path code without\n    304                 # performance penalty for the synchronous case.\n    305                 try:\n    306                     orig_stack_contexts = stack_context._state.contexts\n--> 307                     yielded = next(result)\n        yielded = undefined\n        result = <generator object dispatch_shell>\n    308                     if stack_context._state.contexts is not orig_stack_contexts:\n    309                         yielded = TracebackFuture()\n    310                         yielded.set_exception(\n    311                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}})\n    256             try:\n    257                 self.pre_handler_hook()\n    258             except Exception:\n    259                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    260             try:\n--> 261                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'fbedfd8a5a5d4f889cb6af724dc1bafd']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}}\n    262             except Exception:\n    263                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    264             except KeyboardInterrupt:\n    265                 # Ctrl-c shouldn't crash the kernel here.\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'fbedfd8a5a5d4f889cb6af724dc1bafd'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    302                 # never actually yields, which in turn allows us to\n    303                 # use \"optional\" coroutines in critical path code without\n    304                 # performance penalty for the synchronous case.\n    305                 try:\n    306                     orig_stack_contexts = stack_context._state.contexts\n--> 307                     yielded = next(result)\n        yielded = undefined\n        result = <generator object execute_request>\n    308                     if stack_context._state.contexts is not orig_stack_contexts:\n    309                         yielded = TracebackFuture()\n    310                         yielded.set_exception(\n    311                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'fbedfd8a5a5d4f889cb6af724dc1bafd'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2024, 7, 5, 16, 21, 27, 504362, tzinfo=datetime.timezone.utc), 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'session': 'fbedfd8a5a5d4f889cb6af724dc1bafd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '38a90166537849b1ada78374eb1added', 'msg_type': 'execute_request', 'parent_header': {}})\n    536             self._publish_execute_input(code, parent, self.execution_count)\n    537 \n    538         reply_content = yield gen.maybe_future(\n    539             self.do_execute(\n    540                 code, silent, store_history,\n--> 541                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    542             )\n    543         )\n    544 \n    545         # Flush output before sending the reply.\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', False, True, {}, True), **kwargs={})\n    302                 # never actually yields, which in turn allows us to\n    303                 # use \"optional\" coroutines in critical path code without\n    304                 # performance penalty for the synchronous case.\n    305                 try:\n    306                     orig_stack_contexts = stack_context._state.contexts\n--> 307                     yielded = next(result)\n        yielded = undefined\n        result = <generator object do_execute>\n    308                     if stack_context._state.contexts is not orig_stack_contexts:\n    309                         yielded = TracebackFuture()\n    310                         yielded.set_exception(\n    311                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    297                             shell.events.trigger('post_run_cell', res)\n    298             else:\n    299                 # runner isn't already running,\n    300                 # make synchronous call,\n    301                 # letting shell dispatch to loop runners\n--> 302                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n'\n        store_history = True\n        silent = False\n    303         finally:\n    304             self._restore_input()\n    305 \n    306         if res.error_before_exec is not None:\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n',), **kwargs={'silent': False, 'store_history': True})\n    534             )\n    535         self.payload_manager.write_payload(payload)\n    536 \n    537     def run_cell(self, *args, **kwargs):\n    538         self._last_traceback = None\n--> 539         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    540 \n    541     def _showtraceback(self, etype, evalue, stb):\n    542         # try to preserve ordering of tracebacks and print statements\n    543         sys.stdout.flush()\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import optuna\\nfrom sklearn.model_selection impor...rint(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\\n', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.Import object>, <_ast.Import object>, <_ast.Import object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.FunctionDef object>, <_ast.FunctionDef object>, ...], cell_name='<ipython-input-2-508d851be536>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 20252119dd8, executio..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000020257738390, file \"<ipython-input-2-508d851be536>\", line 61>\n        result = <ExecutionResult object at 20252119dd8, executio..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000020257738390, file \"<ipython-input-2-508d851be536>\", line 61>, result=<ExecutionResult object at 20252119dd8, executio..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000020257738390, file \"<ipython-input-2-508d851be536>\", line 61>\n        self.user_global_ns = {'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))'], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'X':          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], '_': '', '__': '', '___': '', ...}\n        self.user_ns = {'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'In': ['', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))', 'import optuna\\nfrom sklearn.model_selection impor...print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))'], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'Out': {}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'X':          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], '_': '', '__': '', '___': '', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<ipython-input-2-508d851be536> in <module>()\n     56     print('随机森林最优参数：\\nbest_params:', study.best_trial.params,\n     57           '随机森林最优得分：\\nbest_score:', study.best_trial.value, '\\n')\n     58     \n     59     return study\n     60 \n---> 61 study_rf = optimizer_optuna_rf(100)\n     62 \n     63 with open('随机森林贝叶斯优化结果.txt', 'w') as f:\n     64     for key, value in study_rf.best_trial.params.items():\n     65         f.write(f'{key}: {value}\\n')\n\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<ipython-input-2-508d851be536> in optimizer_optuna_rf(n_trials=100)\n     49     validation_loss = cross_validate(reg, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n     50     return np.mean(validation_loss['test_score'])\n     51 \n     52 def optimizer_optuna_rf(n_trials):\n     53     study = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20, n_ei_candidates=30), direction='maximize')\n---> 54     study.optimize(optuna_objective_rf, n_trials=n_trials, show_progress_bar=True)\n     55     \n     56     print('随机森林最优参数：\\nbest_params:', study.best_trial.params,\n     57           '随机森林最优得分：\\nbest_score:', study.best_trial.value, '\\n')\n     58     \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\study.py in optimize(self=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, n_trials=100, timeout=None, n_jobs=1, catch=(), callbacks=None, gc_after_trial=False, show_progress_bar=True)\n    423             timeout=timeout,\n    424             n_jobs=n_jobs,\n    425             catch=catch,\n    426             callbacks=callbacks,\n    427             gc_after_trial=gc_after_trial,\n--> 428             show_progress_bar=show_progress_bar,\n        show_progress_bar = True\n    429         )\n    430 \n    431     def ask(\n    432         self, fixed_distributions: Optional[Dict[str, BaseDistribution]] = None\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py in _optimize(study=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, n_trials=100, timeout=None, n_jobs=1, catch=(), callbacks=None, gc_after_trial=False, show_progress_bar=True)\n     71                 catch,\n     72                 callbacks,\n     73                 gc_after_trial,\n     74                 reseed_sampler_rng=False,\n     75                 time_start=None,\n---> 76                 progress_bar=progress_bar,\n        progress_bar = <optuna.progress_bar._ProgressBar object>\n     77             )\n     78         else:\n     79             if n_jobs == -1:\n     80                 n_jobs = os.cpu_count() or 1\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py in _optimize_sequential(study=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, n_trials=100, timeout=None, catch=(), callbacks=None, gc_after_trial=False, reseed_sampler_rng=False, time_start=datetime.datetime(2024, 7, 6, 0, 21, 29, 101232), progress_bar=<optuna.progress_bar._ProgressBar object>)\n    155             elapsed_seconds = (datetime.datetime.now() - time_start).total_seconds()\n    156             if elapsed_seconds >= timeout:\n    157                 break\n    158 \n    159         try:\n--> 160             frozen_trial = _run_trial(study, func, catch)\n        frozen_trial = FrozenTrial(number=2, values=[-0.001057478380321...rial_id=2, state=TrialState.COMPLETE, value=None)\n        study = <optuna.study.study.Study object>\n        func = <function optuna_objective_rf>\n        catch = ()\n    161         finally:\n    162             # The following line mitigates memory problems that can be occurred in some\n    163             # environments (e.g., services that use computing containers such as CircleCI).\n    164             # Please refer to the following PR for further details:\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\optuna\\study\\_optimize.py in _run_trial(study=<optuna.study.study.Study object>, func=<function optuna_objective_rf>, catch=())\n    191     func_err: Optional[Union[Exception, KeyboardInterrupt]] = None\n    192     func_err_fail_exc_info: Optional[Any] = None\n    193 \n    194     with get_heartbeat_thread(trial._trial_id, study._storage):\n    195         try:\n--> 196             value_or_values = func(trial)\n        value_or_values = None\n        func = <function optuna_objective_rf>\n        trial = <optuna.trial._trial.Trial object>\n    197         except exceptions.TrialPruned as e:\n    198             # TODO(mamu): Handle multi-objective cases.\n    199             state = TrialState.PRUNED\n    200             func_err = e\n\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<ipython-input-2-508d851be536> in optuna_objective_rf(trial=<optuna.trial._trial.Trial object>)\n     44                                 random_state=1412,\n     45                                 verbose=False,\n     46                                 n_jobs=-1)\n     47     \n     48     cv = KFold(n_splits=5, shuffle=True, random_state=1412)\n---> 49     validation_loss = cross_validate(reg, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n     50     return np.mean(validation_loss['test_score'])\n     51 \n     52 def optimizer_optuna_rf(n_trials):\n     53     study = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20, n_ei_candidates=30), direction='maximize')\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, groups=None, scoring='neg_mean_squared_error', cv=KFold(n_splits=5, random_state=1412, shuffle=True), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score='warn')\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=1412, shuffle=True)>\n        X =          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns]\n        y = 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nJoblibValueError                                   Sat Jul  6 00:26:08 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in retrieve(self=Parallel(n_jobs=-1))\n    735 %s\"\"\" % (this_report, exception.message)\n    736                     # Convert this to a JoblibException\n    737                     exception_type = _mk_exception(exception.etype)[0]\n    738                     exception = exception_type(report)\n    739 \n--> 740                     raise exception\n        exception = undefined\n    741 \n    742     def __call__(self, iterable):\n    743         if self._jobs:\n    744             raise ValueError('This Parallel instance is already running')\n\nJoblibValueError: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\程大水\\Jupyter\\<string> in <module>()\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in spawn_main(pipe_handle=2796, parent_pid=5364, tracker_fd=None)\n    100         fd = msvcrt.open_osfhandle(new_handle, os.O_RDONLY)\n    101     else:\n    102         from . import semaphore_tracker\n    103         semaphore_tracker._semaphore_tracker._fd = tracker_fd\n    104         fd = pipe_handle\n--> 105     exitcode = _main(fd)\n        exitcode = undefined\n        fd = 3\n    106     sys.exit(exitcode)\n    107 \n    108 \n    109 def _main(fd):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\spawn.py in _main(fd=3)\n    113             preparation_data = reduction.pickle.load(from_parent)\n    114             prepare(preparation_data)\n    115             self = reduction.pickle.load(from_parent)\n    116         finally:\n    117             del process.current_process()._inheriting\n--> 118     return self._bootstrap()\n        self._bootstrap = <bound method BaseProcess._bootstrap of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    119 \n    120 \n    121 def _check_not_importing_main():\n    122     if getattr(process.current_process(), '_inheriting', False):\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in _bootstrap(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n    253                 # delay finalization of the old process object until after\n    254                 # _run_after_forkers() is executed\n    255                 del old_process\n    256             util.info('child process calling self.run()')\n    257             try:\n--> 258                 self.run()\n        self.run = <bound method BaseProcess.run of <SpawnProcess(SpawnPoolWorker-52, started daemon)>>\n    259                 exitcode = 0\n    260             finally:\n    261                 util._exit_function()\n    262         except SystemExit as e:\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\process.py in run(self=<SpawnProcess(SpawnPoolWorker-52, started daemon)>)\n     88     def run(self):\n     89         '''\n     90         Method to be run in sub-process; can be overridden in sub-class\n     91         '''\n     92         if self._target:\n---> 93             self._target(*self._args, **self._kwargs)\n        self._target = <function worker>\n        self._args = (<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, <sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, None, (), None, True)\n        self._kwargs = {}\n     94 \n     95     def start(self):\n     96         '''\n     97         Start child process\n\n...........................................................................\nD:\\anaconda\\lib\\multiprocessing\\pool.py in worker(inqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, outqueue=<sklearn.externals.joblib.pool.CustomizablePicklingQueue object>, initializer=None, initargs=(), maxtasks=None, wrap_exception=True)\n    114             util.debug('worker got sentinel -- exiting')\n    115             break\n    116 \n    117         job, i, func, args, kwds = task\n    118         try:\n--> 119             result = (True, func(*args, **kwds))\n        result = undefined\n        func = <sklearn.externals.joblib._parallel_backends.SafeFunction object>\n        args = ()\n        kwds = {}\n    120         except Exception as e:\n    121             if wrap_exception and func is not _helper_reraises_exception:\n    122                 e = ExceptionWithTraceback(e, e.__traceback__)\n    123             result = (False, e)\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __call__(self=<sklearn.externals.joblib._parallel_backends.SafeFunction object>, *args=(), **kwargs={})\n    345     def __init__(self, func):\n    346         self.func = func\n    347 \n    348     def __call__(self, *args, **kwargs):\n    349         try:\n--> 350             return self.func(*args, **kwargs)\n        self.func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        args = ()\n        kwargs = {}\n    351         except KeyboardInterrupt:\n    352             # We capture the KeyboardInterrupt and reraise it as\n    353             # something different, as multiprocessing does not\n    354             # interrupt processing for a KeyboardInterrupt\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None), {'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False),          Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], 0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=         Monsoon Intensity  Topography Drainage ... 6               9  \n\n[1048575 rows x 20 columns], y=0          0.445\n1          0.450\n2          0.5...lood Probability, Length: 1048575, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([      0,       1,       2, ..., 1048572, 1048573, 1048574]), test=array([      3,       4,      17, ..., 1048554, 1048562, 1048567]), verbose=0, parameters=None, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...412,\n           verbose=False, warm_start=False)>\n        X_train =          Monsoon Intensity  Topography Drainage ...  6               9  \n\n[838860 rows x 20 columns]\n        y_train = 0          0.445\n1          0.450\n2          0.5...Flood Probability, Length: 838860, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 28\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul  6 00:26:05 2024\nPID: 17504                             Python 3.6.4: D:\\anaconda\\python.exe\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29), {'class_weight': None, 'verbose': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), None, 0, 29)\n        kwargs = {'class_weight': None, 'verbose': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...1412,\n           verbose=False, warm_start=False), X=array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]]), sample_weight=None, tree_idx=0, n_trees=29, verbose=False, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1630984966, splitter='best')>\n        X = array([[5., 8., 5., ..., 5., 7., 3.],\n       [6....   [5., 3., 4., ..., 1., 6., 9.]], dtype=float32)\n        y = array([[0.445],\n       [0.45 ],\n       [0.53 ],\n...\n       [0.5  ],\n       [0.45 ],\n       [0.535]])\n        sample_weight = None\n        curr_sample_weight = array([3., 0., 0., ..., 2., 2., 1.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nD:\\anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1630984966, splitter='best'), X=array([[5., 8., ..., 7., 3.],\n       [6., 7., ......],\n       [5., 3., ..., 6., 9.]], dtype=float32), y=array([[0.445],\n       [0.45 ],\n       ...,\n       [0.45 ],\n       [0.535]]), sample_weight=array([3., 0., ..., 2., 1.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before trails')\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# 计时开始\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv('train.csv')\n",
    "X = data.iloc[:, 1:-1]  # 忽略第一列 ID 和最后一列洪水发生概率\n",
    "y = data.iloc[:, -1]    # 最后一列是洪水发生概率\n",
    "\n",
    "# 创建模型得分分布图\n",
    "def plot_model_scores(scores, title, filename):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(scores, kde=True, bins=20)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# 贝叶斯优化随机森林\n",
    "def optuna_objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 30, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    max_features = trial.suggest_int('max_features', 10, 30, 1)\n",
    "    \n",
    "    reg = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                max_depth=max_depth,\n",
    "                                max_features=max_features,\n",
    "                                random_state=1412,\n",
    "                                verbose=False,\n",
    "                                n_jobs=-1)\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1412)\n",
    "    validation_loss = cross_validate(reg, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    return np.mean(validation_loss['test_score'])\n",
    "\n",
    "def optimizer_optuna_rf(n_trials):\n",
    "    study = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20, n_ei_candidates=30), direction='maximize')\n",
    "    study.optimize(optuna_objective_rf, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    print('随机森林最优参数：\\nbest_params:', study.best_trial.params,\n",
    "          '随机森林最优得分：\\nbest_score:', study.best_trial.value, '\\n')\n",
    "    \n",
    "    return study\n",
    "\n",
    "study_rf = optimizer_optuna_rf(100)\n",
    "\n",
    "with open('随机森林贝叶斯优化结果.txt', 'w') as f:\n",
    "    for key, value in study_rf.best_trial.params.items():\n",
    "        f.write(f'{key}: {value}\\n')\n",
    "    f.write(f'Best Score: {study_rf.best_trial.value}\\n')\n",
    "\n",
    "plot_model_scores([trial.value for trial in study_rf.trials], 'Random Forest Scores Distribution', 'random_forest_scores.png')\n",
    "\n",
    "# 贝叶斯优化决策树\n",
    "def optuna_objective_dtr(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 10, 30, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 10, 30, 1)\n",
    "    max_features = trial.suggest_int('max_features', 10, 30, 1)\n",
    "    \n",
    "    dtr = DecisionTreeRegressor(max_depth=max_depth,\n",
    "                                max_features=max_features,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                random_state=1412)\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1412)\n",
    "    validation_loss = cross_validate(dtr, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    return np.mean(validation_loss['test_score'])\n",
    "\n",
    "def optimizer_optuna_dtr(n_trials):\n",
    "    study = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20, n_ei_candidates=30), direction='maximize')\n",
    "    study.optimize(optuna_objective_dtr, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    print('决策树最优参数：\\nbest_params:', study.best_trial.params,\n",
    "          '决策树最优得分：\\nbest_score:', study.best_trial.value, '\\n')\n",
    "    \n",
    "    return study\n",
    "\n",
    "study_dtr = optimizer_optuna_dtr(100)\n",
    "\n",
    "with open('决策树贝叶斯优化结果.txt', 'w') as f:\n",
    "    for key, value in study_dtr.best_trial.params.items():\n",
    "        f.write(f'{key}: {value}\\n')\n",
    "    f.write(f'Best Score: {study_dtr.best_trial.value}\\n')\n",
    "\n",
    "plot_model_scores([trial.value for trial in study_dtr.trials], 'Decision Tree Scores Distribution', 'decision_tree_scores.png')\n",
    "\n",
    "# 贝叶斯优化梯度提升树\n",
    "def optuna_objective_gbr(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(max_depth=max_depth,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    n_estimators=n_estimators,\n",
    "                                    subsample=subsample,\n",
    "                                    random_state=1412)\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1412)\n",
    "    validation_loss = cross_validate(gbr, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    return np.mean(validation_loss['test_score'])\n",
    "\n",
    "def optimizer_optuna_gbr(n_trials):\n",
    "    study = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20, n_ei_candidates=30), direction='maximize')\n",
    "    study.optimize(optuna_objective_gbr, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    print('梯度提升树最优参数：\\nbest_params:', study.best_trial.params,\n",
    "          '梯度提升树最优得分：\\nbest_score:', study.best_trial.value, '\\n')\n",
    "    \n",
    "    return study\n",
    "\n",
    "study_gbr = optimizer_optuna_gbr(100)\n",
    "\n",
    "with open('梯度提升树贝叶斯优化结果.txt', 'w') as f:\n",
    "    for key, value in study_gbr.best_trial.params.items():\n",
    "        f.write(f'{key}: {value}\\n')\n",
    "    f.write(f'Best Score: {study_gbr.best_trial.value}\\n')\n",
    "\n",
    "plot_model_scores([trial.value for trial in study_gbr.trials], 'Gradient Boosting Scores Distribution', 'gradient_boosting_scores.png')\n",
    "\n",
    "# 计时结束\n",
    "end_time = time.time()\n",
    "\n",
    "# 输出执行时间\n",
    "execution_time = end_time - start_time\n",
    "print(\"模型训练执行时间: {:.2f}秒\".format(execution_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
